# Portfolio

# Neural transfer project

 # Setup (come funziona)

Il Trasferimento di Stile Neurale (NTS) Ã¨ una tecnica che genera unâ€™immagine â€œibridaâ€ combinando il contenuto di un'immagine (es. foto) con lo stile di un'altra (es. dipinto). Si usa una CNN pre-addestrata (VGG19): il contenuto Ã¨ rappresentato dalle attivazioni dei layer profondi (catturano struttura/oggetti), mentre lo stile Ã¨ modellato con le matrici di Gram delle feature su piÃ¹ layer (catturano texture e correlazioni tra filtri). Lâ€™immagine generata viene ottimizzata per minimizzare una loss totale 
ð¿=ð›¼ð¿ð‘ð‘œð‘›ð‘¡ð‘’ð‘›ð‘¡+ð›½ð¿ð‘ ð‘¡ð‘¦ð‘™ð‘’L=Î±Lcontent+Î²Lstyle
, cosÃ¬ da bilanciare fedeltÃ  al contenuto e coerenza stilistica.

Si Ã¨ usato VGG19 considerando solo i layer convoluzionali. Per studiare la fusione stileâ€“contenuto:

contenuto = foto di TimothÃ©e Chalamet; 
stile = â€œNotte stellataâ€ (Van Gogh), â€œLâ€™Urloâ€ (Munch), â€œConvergenceâ€ (Pollock), .

# Risultati ottenuti

Dalle ricostruzioni emerge che i primi layer conservano dettagli locali (bordi/texture fini), mentre i layer profondi astraggono la struttura globale/semantica del contenuto. Per lo stile, i layer superficiali rendono pattern minuti, quelli profondi consolidano coerenza stilistica globale. Nelle immagini finali stile+contenuto, il bilanciamento Î±/Î² e i pesi dei layer di contenuto determinano quanta texture â€œinvadeâ€ la scena: enfatizzare conv1 produce trame fini; conv5 dÃ  tratti stilistici ampi. Tracciando le perdite, lo stile domina la loss nonostante Î²â‰ªÎ±, perchÃ© partendo dalla foto il termine di contenuto Ã¨ inizialmente piccolo. 


# Prerequisiti:

- Python 3.9+

- pip aggiornato

- (Opzionale) GPU NVIDIA con driver aggiornati

  ---

# Guida d'utilizzo

> Esegui i comandi dalla cartella del progetto (es. `C:\NTS`).  
> Le immagini di input vanno in `data/`, lâ€™output viene salvato in `results/`.

## 1) Preparazione ambiente

### Windows (PowerShell)
```powershell
D:
cd NTS
python -m venv .venv
.\.venv\Scripts\Activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### macOS/Linux (Bash)
```
cd ~/NTS
python -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```
# 2) Inserisci i dati

Metti le immagini in data/, ad esempio:

```
data/Themothee.png
data/Notte stellata.jpg
```

>Nomi con spazi sono ok se usi le virgolette nei comandi.
>Le immagini RGBA vengono convertite in RGB dal loader.

#3) Esecuzione
Avvio con i default

Se i file sopra esistono:
```
python .\src\core.py
```
Avvio con parametri personalizzati
### Windows (PowerShell) 
```
python .\src\core.py --content_path "data\YourContent.jpg" --style_path "data\Notte stellata.jpg" --output_path "results\out.png" --imsize 384 --steps 400 --lr 0.02 --alpha 1.0 --beta 80000 --init content
```

### macOS / Linux (bash)
```
python ./src/core.py --content_path "data/YourContent.jpg" --style_path "data/Notte stellata.jpg" --output_path "results/out.png" --imsize 384 --steps 400 --lr 0.02 --alpha 1.0 --beta 80000 --init content
```

Parametri principali

-content_path / --style_path / --output_path

-imsize â†’ 256 / 384 / 512 (piÃ¹ grande = piÃ¹ lento, piÃ¹ dettagli)

-steps â†’ iterazioni di ottimizzazione (200â€“1000 per test rapidi)

-lr â†’ learning rate (0.01â€“0.05 tipico)

-alpha â†’ peso contenuto

-beta â†’ peso stile (di solito alto: 50_000â€“100_000)

-init â†’ content (stabile) o noise (piÃ¹ creativo)

Durante il run vedrai log della loss; lâ€™immagine viene salvata in --output_path.
